# Hadoop overview
    Hadoop is an Apache open source framework written in java that allows distributed processing of large datasets across clusters of computers using simple programming models. The Hadoop framework application works in an environment that provides distributed storage and computation across clusters of computers. Hadoop is designed to scale up from single server to thousands of machines, each offering local computation and storage.
# Hadoop Architecture
At its core, Hadoop has two major layers namely âˆ’

    - Processing/Computation layer (MapReduce), and
    - Storage layer (Hadoop Distributed File System).


![Architecture](../image/hadoop-1.png)

# Hadoop install:
   1. Install by File
   2. Install by Docker
        - Docker installation can be verified by

```
           docker --version
```

# Quick commandline: 

# Hadoop tip:



# Link refer:
  - https://www.guru99.com/how-to-install-hadoop.html
  - https://www.guru99.com/data-engineer-interview-questions.html